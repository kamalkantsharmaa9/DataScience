{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "T1X_QWiDztSG"
   },
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input,decode_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pgeMHkGd07gT",
    "outputId": "7797004e-1f71-45f7-acfc-6803a556268d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 0s 0us/step\n",
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=MobileNet(weights='imagenet',include_top=False,classes=1000)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "jt17jYVI2W1g",
    "outputId": "b9a9dc72-b3d5-4a97-f8e8-c3c9d15c0c64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-4de3f764-aabb-45e8-8283-944c4718c5f2\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-4de3f764-aabb-45e8-8283-944c4718c5f2\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Train.zip to Train.zip\n"
     ]
    }
   ],
   "source": [
    "##now i will create my train dataset \n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJz47YjIMFqX"
   },
   "outputs": [],
   "source": [
    "!unzip Train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxnTJ9G5M6zU",
    "outputId": "46d28a59-a049-4bd0-cf13-311b40ae5227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "029d0c659dc448f49993648b024e615c.jpg  c562bf7015de45f59332f711bb81e926.jpg\n",
      "0598db9a1de245db9719661466001511.jpg  d1d381e5f2df42a0973e0251751e1a14.jpg\n",
      "0598e2f5a108470e9fced4079b1105ca.jpg  d995b3fc3cbe47e4811493dd8f1c4ada.jpg\n",
      "065e79403c774ea288646043465a393f.jpg  dbbd1c859b8d48878421e058f2d7e26c.jpg\n",
      "0a15b831d1b947fda035aaf637c58215.jpg  e374261001b84fdbbfb7e2427c0f2c9c.jpg\n",
      "0e87220a99a54ac296e49ee01cec144e.jpg  e8d4cf4ee37a471bb92ee42e298eb692.jpg\n",
      "0eab1e1f744340fa87268f2b558c7ccf.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-10.jpg\n",
      "11c991617d56476ba4d926a87d7fc684.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-14.jpg\n",
      "1727be397509465f9d3dafbf3849a8f1.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-15.jpg\n",
      "25adea61e7624a84a8fbe88d7dcbeb6e.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-16.jpg\n",
      "25d15a304c354f3e8064249cf704370d.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-17.jpg\n",
      "263b3cb088e5448e99335fbda8f73ee7.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-18.jpg\n",
      "35933037ff854c2784e5199f6dc8a728.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-19.jpg\n",
      "4197d539263d43fa95adbd592cde7138.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-1.jpg\n",
      "41e07cd07e9a4d25b9ad5a9ca08f3b5e.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-20.jpg\n",
      "4265d1d030e4400a9eb37d520ffa1646.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-21.jpg\n",
      "45fab61f4a6747138ec1f89e24ac289b.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-22.jpg\n",
      "4b4f424282e847b38fdf9f9ae4e47332.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-23.jpg\n",
      "4c7989f0dc414bb189a4990659dc0e3f.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-24.jpg\n",
      "523b396d18584c35a45823b6a145eff6.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-25.jpg\n",
      "79f94a276b9a4e06b4884c3b77ef4622.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-26.jpg\n",
      "7eaf21277f854895bc70dc9568c2aa88.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-27.jpg\n",
      "7fb69a33c0ca4c458812233bb4084b01.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-28.jpg\n",
      "8432766c5438408984341c999e0ebac2.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-29.jpg\n",
      "86220fd195184c48a2a6ae8e5e7830e1.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-31.jpg\n",
      "8c1a69bc6f3746bdabacd8d658041dcb.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-33.jpg\n",
      "8e1000fe38a640c2b74abc74e93eb049.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-34.jpg\n",
      "91a6d66ed71e45c4a7a5a7917ab44666.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-36.jpg\n",
      "91fab894d10b4a33b1bdf7c9f7990137.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-37.jpg\n",
      "9509421af9a04d038cfca99ad0f2b885.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-39.jpg\n",
      "952fb87af3e14dfca7cbacad41457e1b.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-3.jpg\n",
      "97ecd443cbf64b31838c723d80b0f1be.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-40.jpg\n",
      "a1eb1fcdf2ea490aa3dc6b49a8c88fd5.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-41.jpg\n",
      "a7712d25c62d4551addb55002d34b891.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-42.jpg\n",
      "b4aa2ac622c348e8843c24229d935d5e.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-5.jpg\n",
      "b4d0b58b819a408894a67093ddde58d9.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-6.jpg\n",
      "b53eb5dbbc274302b6dc9f19a4759275.jpg  ef7f7eeaa897478bbe1df7b0bb0522cb-8.jpg\n",
      "bb6be0f790654421a4456b1b9242e0a1.jpg  f403dcd3136643e4b43c7d01e14494bc.jpg\n",
      "bce4a9f8a23b49fab63986dced8b8292.jpg  f6de83f1ed034679bf49b84e0af203ce.jpg\n",
      "bf5489f37c6f4dd688e59254d3bddcab.jpg  f9b2de8410924cb49e75c0178b15103f.jpg\n"
     ]
    }
   ],
   "source": [
    "!ls 'Train (1)'/Aerodactyl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-noSLjA2VxZ",
    "outputId": "5d18dec6-0b5c-40ca-ec57-8aed517697af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 9, 0, ..., 8, 1, 4])"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from  pathlib import Path\n",
    "from random import shuffle\n",
    "from keras.utils import np_utils\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "image_data=[]\n",
    "labels=[]\n",
    "label_dict={}\n",
    "p=Path('Train (1)')\n",
    "dirs=list(p.glob(\"*\"))\n",
    "index=0\n",
    "for folder in dirs:\n",
    "    label=str(folder).split('\\\\')[-1]\n",
    "    if label in label_dict.keys():\n",
    "        pass\n",
    "    else:\n",
    "        label_dict.update({label:index})\n",
    "        index+=1\n",
    "    for img_path in folder.glob(\"*.jpg\"):\n",
    "        img=cv2.imread(str(img_path))\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        img=cv2.resize(img,(224,224))\n",
    "        image_data.append(img)\n",
    "        labels.append(int(label_dict[label]))\n",
    "image_data=np.array(image_data)\n",
    "labels=np.array(labels)\n",
    "label_dict\n",
    "combine=list(zip(image_data,labels))\n",
    "random.shuffle(combine)\n",
    "image_data[:],labels[:]=zip(*combine)\n",
    "x=np.array(image_data)\n",
    "y=np_utils.to_categorical(labels,index+1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V0KCgtQ7T2pK",
    "outputId": "5bd1d8c9-7116-49a9-e81c-699bc0299bb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1287,)"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2APm3le62FPi"
   },
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input,decode_predictions\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "model=MobileNet(weights='imagenet',include_top=True,classes=1000)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "DCu9ZUmqLzIq",
    "outputId": "dd8851ab-a9a7-4c1e-c18e-5670487c15ab"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-2ece85db1f13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mav1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfc1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mav1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfc2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2685\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2686\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    221\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer global_average_pooling2d_15 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 1000)"
     ]
    }
   ],
   "source": [
    "av1=GlobalAveragePooling2D()(model.output)\n",
    "fc1=Dense(256,activation='relu')(av1)\n",
    "d1=Dropout(0.5)(fc1)\n",
    "fc2=Dense(index+1,activation='softmax')(d1)\n",
    "model_new=Model(inputs=model.inputs,outputs=fc2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "RYHRmjZ0Q42F"
   },
   "outputs": [],
   "source": [
    "adam=Adam(lr=0.0003)\n",
    "model_new.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfdhSu8VOi2O"
   },
   "outputs": [],
   "source": [
    "for ix in range(len(model_new.layers)):\n",
    "  print(ix,model_new.layers[ix])\n",
    "  \n",
    "\n",
    "#model_new.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "6OTIJEuKRWyp"
   },
   "outputs": [],
   "source": [
    "for ix in range(80):\n",
    "  model_new.layers[ix].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ys51GoWrWTr8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VE53NXmRm3Z"
   },
   "outputs": [],
   "source": [
    "model_new.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvPevWZvSkrh",
    "outputId": "9c609d8a-9856-4e5d-f443-1dd75b6b44de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37/37 [==============================] - 12s 234ms/step - loss: 2.5390 - accuracy: 0.2281 - val_loss: 5.7172 - val_accuracy: 0.1705\n",
      "Epoch 2/20\n",
      "37/37 [==============================] - 8s 216ms/step - loss: 1.7248 - accuracy: 0.4386 - val_loss: 3.7271 - val_accuracy: 0.1085\n",
      "Epoch 3/20\n",
      "37/37 [==============================] - 8s 212ms/step - loss: 1.5380 - accuracy: 0.5177 - val_loss: 3.0638 - val_accuracy: 0.0853\n",
      "Epoch 4/20\n",
      "37/37 [==============================] - 8s 207ms/step - loss: 1.4982 - accuracy: 0.4857 - val_loss: 3.1735 - val_accuracy: 0.1240\n",
      "Epoch 5/20\n",
      "37/37 [==============================] - 8s 203ms/step - loss: 1.4044 - accuracy: 0.5393 - val_loss: 3.2947 - val_accuracy: 0.1163\n",
      "Epoch 6/20\n",
      "37/37 [==============================] - 7s 201ms/step - loss: 1.3251 - accuracy: 0.5439 - val_loss: 3.1682 - val_accuracy: 0.1240\n",
      "Epoch 7/20\n",
      "37/37 [==============================] - 7s 199ms/step - loss: 1.2575 - accuracy: 0.5274 - val_loss: 3.5502 - val_accuracy: 0.0853\n",
      "Epoch 8/20\n",
      "37/37 [==============================] - 7s 199ms/step - loss: 1.2116 - accuracy: 0.5159 - val_loss: 5.0558 - val_accuracy: 0.1240\n",
      "Epoch 9/20\n",
      "37/37 [==============================] - 7s 199ms/step - loss: 1.1897 - accuracy: 0.5450 - val_loss: 3.7210 - val_accuracy: 0.1008\n",
      "Epoch 10/20\n",
      "37/37 [==============================] - 7s 200ms/step - loss: 1.0672 - accuracy: 0.5841 - val_loss: 4.1415 - val_accuracy: 0.1318\n",
      "Epoch 11/20\n",
      "37/37 [==============================] - 7s 201ms/step - loss: 1.1019 - accuracy: 0.5279 - val_loss: 4.1850 - val_accuracy: 0.1008\n",
      "Epoch 12/20\n",
      "37/37 [==============================] - 7s 203ms/step - loss: 1.0252 - accuracy: 0.5701 - val_loss: 5.0185 - val_accuracy: 0.1008\n",
      "Epoch 13/20\n",
      "37/37 [==============================] - 8s 204ms/step - loss: 1.0621 - accuracy: 0.5491 - val_loss: 4.2943 - val_accuracy: 0.1008\n",
      "Epoch 14/20\n",
      "37/37 [==============================] - 8s 204ms/step - loss: 1.0603 - accuracy: 0.5339 - val_loss: 4.8583 - val_accuracy: 0.1395\n",
      "Epoch 15/20\n",
      "37/37 [==============================] - 8s 204ms/step - loss: 1.0220 - accuracy: 0.5423 - val_loss: 5.5399 - val_accuracy: 0.1008\n",
      "Epoch 16/20\n",
      "37/37 [==============================] - 8s 204ms/step - loss: 0.9973 - accuracy: 0.5641 - val_loss: 5.1272 - val_accuracy: 0.1318\n",
      "Epoch 17/20\n",
      "37/37 [==============================] - 7s 203ms/step - loss: 0.9561 - accuracy: 0.5721 - val_loss: 4.9216 - val_accuracy: 0.1085\n",
      "Epoch 18/20\n",
      "37/37 [==============================] - 7s 202ms/step - loss: 0.9649 - accuracy: 0.5797 - val_loss: 7.2302 - val_accuracy: 0.1163\n",
      "Epoch 19/20\n",
      "37/37 [==============================] - 7s 202ms/step - loss: 0.9831 - accuracy: 0.5287 - val_loss: 5.2978 - val_accuracy: 0.0853\n",
      "Epoch 20/20\n",
      "37/37 [==============================] - 7s 202ms/step - loss: 0.9465 - accuracy: 0.5637 - val_loss: 5.4453 - val_accuracy: 0.0853\n"
     ]
    }
   ],
   "source": [
    "hist=model_new.fit(x,y,shuffle=True,validation_split=0.10,batch_size=32,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONmTAYcyUiRo"
   },
   "outputs": [],
   "source": [
    "####now just creating a resneet here\n",
    "## you can say a new project#####################################################################################################\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "model=ResNet50(weights='imagenet',include_top=False,classes=1000)\n",
    "model.summary()\n",
    "av1=GlobalAveragePooling2D()(model.output)\n",
    "fc1=Dense(256,activation='relu')(av1)\n",
    "d1=Dropout(0.5)(fc1)\n",
    "fc2=Dense(index+1,activation='softmax')(d1)\n",
    "model_new=Model(inputs=model.inputs,outputs=fc2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARtyQwl4WA8t"
   },
   "outputs": [],
   "source": [
    "model_new.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
    "for ix in range(len(model_new.layers)):\n",
    "  print(ix,model_new.layers[ix])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "M9CAq9mJWVxR"
   },
   "outputs": [],
   "source": [
    "for ix in range(169):\n",
    "  model_new.layers[ix].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bticp5TWiX1",
    "outputId": "b40c1aea-a581-4a23-9882-69ee74f76096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37/37 [==============================] - 19s 358ms/step - loss: 2.7063 - accuracy: 0.2009 - val_loss: 1105.0135 - val_accuracy: 0.0930\n",
      "Epoch 2/20\n",
      "37/37 [==============================] - 12s 323ms/step - loss: 2.2208 - accuracy: 0.2146 - val_loss: 27.3900 - val_accuracy: 0.1240\n",
      "Epoch 3/20\n",
      "37/37 [==============================] - 12s 334ms/step - loss: 2.1068 - accuracy: 0.2742 - val_loss: 110.2603 - val_accuracy: 0.1395\n",
      "Epoch 4/20\n",
      "37/37 [==============================] - 12s 337ms/step - loss: 1.9517 - accuracy: 0.3367 - val_loss: 4.6106 - val_accuracy: 0.1008\n",
      "Epoch 5/20\n",
      "37/37 [==============================] - 12s 328ms/step - loss: 1.8878 - accuracy: 0.3735 - val_loss: 3.5153 - val_accuracy: 0.1628\n",
      "Epoch 6/20\n",
      "37/37 [==============================] - 12s 323ms/step - loss: 1.7858 - accuracy: 0.4179 - val_loss: 2.5826 - val_accuracy: 0.1240\n",
      "Epoch 7/20\n",
      "37/37 [==============================] - 12s 322ms/step - loss: 1.7309 - accuracy: 0.4259 - val_loss: 2.7932 - val_accuracy: 0.1395\n",
      "Epoch 8/20\n",
      "37/37 [==============================] - 12s 323ms/step - loss: 1.7634 - accuracy: 0.4221 - val_loss: 3.3096 - val_accuracy: 0.1318\n",
      "Epoch 9/20\n",
      "37/37 [==============================] - 12s 326ms/step - loss: 1.7393 - accuracy: 0.4079 - val_loss: 3.1011 - val_accuracy: 0.1008\n",
      "Epoch 10/20\n",
      "37/37 [==============================] - 12s 328ms/step - loss: 1.6307 - accuracy: 0.4667 - val_loss: 3.7126 - val_accuracy: 0.1318\n",
      "Epoch 11/20\n",
      "37/37 [==============================] - 12s 329ms/step - loss: 1.5116 - accuracy: 0.5030 - val_loss: 3.2134 - val_accuracy: 0.1395\n",
      "Epoch 12/20\n",
      "37/37 [==============================] - 12s 327ms/step - loss: 1.5731 - accuracy: 0.4929 - val_loss: 3.0788 - val_accuracy: 0.1163\n",
      "Epoch 13/20\n",
      "37/37 [==============================] - 12s 327ms/step - loss: 1.5954 - accuracy: 0.4872 - val_loss: 2.5849 - val_accuracy: 0.0930\n",
      "Epoch 14/20\n",
      "37/37 [==============================] - 12s 325ms/step - loss: 1.5164 - accuracy: 0.5131 - val_loss: 2.9240 - val_accuracy: 0.1008\n",
      "Epoch 15/20\n",
      "37/37 [==============================] - 12s 325ms/step - loss: 1.5304 - accuracy: 0.4944 - val_loss: 2.9767 - val_accuracy: 0.1085\n",
      "Epoch 16/20\n",
      "37/37 [==============================] - 12s 325ms/step - loss: 1.4242 - accuracy: 0.5376 - val_loss: 3.8087 - val_accuracy: 0.0930\n",
      "Epoch 17/20\n",
      "37/37 [==============================] - 12s 326ms/step - loss: 1.4716 - accuracy: 0.5109 - val_loss: 3.4130 - val_accuracy: 0.1473\n",
      "Epoch 18/20\n",
      "37/37 [==============================] - 12s 327ms/step - loss: 1.4156 - accuracy: 0.5261 - val_loss: 4.3747 - val_accuracy: 0.1318\n",
      "Epoch 19/20\n",
      "37/37 [==============================] - 12s 327ms/step - loss: 1.2714 - accuracy: 0.5494 - val_loss: 2.9793 - val_accuracy: 0.1163\n",
      "Epoch 20/20\n",
      "37/37 [==============================] - 12s 328ms/step - loss: 1.3136 - accuracy: 0.5556 - val_loss: 3.8286 - val_accuracy: 0.1395\n"
     ]
    }
   ],
   "source": [
    "hist2=model_new.fit(x,y,shuffle=True,validation_split=0.10,batch_size=32,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9LQ_qSCdWpca",
    "outputId": "c5fc387b-85a8-41e2-bcae-5d05ff92f6a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 52, 52, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 23, 23, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_16  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,638,318\n",
      "Trainable params: 1,638,318\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#####creating a whole new model by seeing these accuracy i m implementing vgg-16\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input,decode_predictions\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D(256,(3,3),activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D(256,(3,3),activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D(256,(3,3),activation='relu'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "6n6YTAq2Zzie"
   },
   "outputs": [],
   "source": [
    "adam=Adam(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLARd5Dcb3Qi",
    "outputId": "db53a078-d9f1-470b-f0ba-c87ba8de5177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 7s 370ms/step - loss: 0.7762 - accuracy: 0.5553 - val_loss: 6.2114 - val_accuracy: 0.1240\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 7s 379ms/step - loss: 0.7882 - accuracy: 0.5691 - val_loss: 5.6977 - val_accuracy: 0.1318\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 7s 391ms/step - loss: 0.7706 - accuracy: 0.5708 - val_loss: 7.9377 - val_accuracy: 0.1240\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 8s 401ms/step - loss: 0.7558 - accuracy: 0.5820 - val_loss: 8.2986 - val_accuracy: 0.1163\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 8s 402ms/step - loss: 0.7726 - accuracy: 0.5622 - val_loss: 9.0081 - val_accuracy: 0.1395\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 7s 392ms/step - loss: 0.7736 - accuracy: 0.5613 - val_loss: 9.1473 - val_accuracy: 0.1163\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 7s 384ms/step - loss: 0.7555 - accuracy: 0.5777 - val_loss: 9.0327 - val_accuracy: 0.1240\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 7s 378ms/step - loss: 0.7852 - accuracy: 0.5544 - val_loss: 10.4571 - val_accuracy: 0.1163\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 7s 374ms/step - loss: 0.7674 - accuracy: 0.5769 - val_loss: 11.6599 - val_accuracy: 0.1008\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 7s 372ms/step - loss: 0.7680 - accuracy: 0.5535 - val_loss: 10.1784 - val_accuracy: 0.1318\n"
     ]
    }
   ],
   "source": [
    "hist=model_new.fit(x,y,validation_split=0.10,batch_size=64,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AGbtnAmcBax"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
